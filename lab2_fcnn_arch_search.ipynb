{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBueJhgWC8wf"
      },
      "source": [
        "# Lab 2: Fully Connected Neural Networks (FCNN)\n",
        "## Machine Learning Hardware Course\n",
        "\n",
        "This lab focuses on the architecture, implementation, and hardware implications of Fully Connected Neural Networks (FCNNs). You will implement FCNNs of varying depths and widths, experiment with different activation functions and regularization techniques, and analyze how architectural choices impact performance, computational requirements, and hardware efficiency.\n",
        "\n",
        "**Note:** This version uses CIFAR-10 dataset for most experiments, with comparison between CIFAR-10 and Fashion MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "logiPtbbC8wi"
      },
      "source": [
        "## PART 1: ENVIRONMENT SETUP\n",
        "\n",
        "In this section, we'll set up our environment and import necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdYKrL0DC8wj"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10, fashion_mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "# Check TensorFlow version and GPU availability\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# If psutil is not installed, uncomment this line:\n",
        "# !pip install psutil\n",
        "\n",
        "# Mount Google Drive (uncomment when running in Colab)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !mkdir -p \"/content/drive/My Drive/ML_Hardware_Course/Lab2\"\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9RJvhZQC8wl"
      },
      "source": [
        "## PART 2: DATASET PREPARATION\n",
        "\n",
        "In this section, we'll load and prepare the CIFAR-10 and Fashion MNIST datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lqBEO7KC8wm"
      },
      "outputs": [],
      "source": [
        "def load_and_prepare_cifar10():\n",
        "    \"\"\"\n",
        "    Load and prepare the CIFAR-10 dataset for training FCNNs.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Training, validation, and test data along with test labels\n",
        "    \"\"\"\n",
        "    # Load CIFAR-10 dataset\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "    # Print original data shapes\n",
        "    print(\"Original CIFAR-10 shapes:\")\n",
        "    print(f\"  X_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"  X_test: {x_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Reshape data (flatten images) - CIFAR-10 has 32x32x3 = 3072 features\n",
        "    x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "    x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "    # Flatten y_train if needed (CIFAR-10 returns shape (n, 1))\n",
        "    y_train = y_train.flatten()\n",
        "    y_test = y_test.flatten()\n",
        "\n",
        "    # One-hot encode labels\n",
        "    y_train_encoded = to_categorical(y_train, 10)\n",
        "    y_test_encoded = to_categorical(y_test, 10)\n",
        "\n",
        "    # Create validation set (10% of training data)\n",
        "    val_size = 5000\n",
        "    x_val = x_train_flat[-val_size:]\n",
        "    y_val = y_train_encoded[-val_size:]\n",
        "    x_train_final = x_train_flat[:-val_size]\n",
        "    y_train_final = y_train_encoded[:-val_size]\n",
        "\n",
        "    print(\"\\nProcessed CIFAR-10 dataset:\")\n",
        "    print(f\"  Training set: {x_train_final.shape}\")\n",
        "    print(f\"  Validation set: {x_val.shape}\")\n",
        "    print(f\"  Test set: {x_test_flat.shape}\")\n",
        "    print(f\"  Input dimension: {x_train_final.shape[1]} (32x32x3)\")\n",
        "\n",
        "    return (x_train_final, y_train_final), (x_val, y_val), (x_test_flat, y_test_encoded), y_test\n",
        "\n",
        "def load_and_prepare_fashion_mnist():\n",
        "    \"\"\"\n",
        "    Load and prepare the Fashion MNIST dataset for training FCNNs.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Training, validation, and test data along with test labels\n",
        "    \"\"\"\n",
        "    # Load Fashion MNIST dataset\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    # Print original data shapes\n",
        "    print(\"\\nOriginal Fashion MNIST shapes:\")\n",
        "    print(f\"  X_train: {x_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"  X_test: {x_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Reshape data (flatten images)\n",
        "    x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "    x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    y_train_encoded = to_categorical(y_train, 10)\n",
        "    y_test_encoded = to_categorical(y_test, 10)\n",
        "\n",
        "    # Create validation set (10% of training data)\n",
        "    val_size = 6000\n",
        "    x_val = x_train_flat[-val_size:]\n",
        "    y_val = y_train_encoded[-val_size:]\n",
        "    x_train_final = x_train_flat[:-val_size]\n",
        "    y_train_final = y_train_encoded[:-val_size]\n",
        "\n",
        "    print(\"\\nProcessed Fashion MNIST dataset:\")\n",
        "    print(f\"  Training set: {x_train_final.shape}\")\n",
        "    print(f\"  Validation set: {x_val.shape}\")\n",
        "    print(f\"  Test set: {x_test_flat.shape}\")\n",
        "\n",
        "    return (x_train_final, y_train_final), (x_val, y_val), (x_test_flat, y_test_encoded), y_test\n",
        "\n",
        "# Define class names for CIFAR-10\n",
        "cifar10_class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
        "                        'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "# Define class names for Fashion MNIST\n",
        "fashion_class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                      'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Load both datasets\n",
        "print(\"Loading CIFAR-10 dataset...\")\n",
        "cifar_train, cifar_val, cifar_test, cifar_y_test = load_and_prepare_cifar10()\n",
        "\n",
        "print(\"\\nLoading Fashion MNIST dataset...\")\n",
        "fashion_train, fashion_val, fashion_test, fashion_y_test = load_and_prepare_fashion_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIaW70bmC8wn"
      },
      "outputs": [],
      "source": [
        "# Display sample images from both datasets\n",
        "def display_samples_cifar10(dataset_name, x_data, y_data, class_names, num_samples=5):\n",
        "    \"\"\"\n",
        "    Display sample images from CIFAR-10 dataset.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(num_samples):\n",
        "        idx = np.random.randint(0, len(x_data))\n",
        "        # Reshape back to original CIFAR-10 format (32, 32, 3)\n",
        "        img = x_data[idx].reshape(32, 32, 3)\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        plt.imshow(img)\n",
        "        class_idx = np.argmax(y_data[idx])\n",
        "        plt.title(f\"{class_names[class_idx]}\")\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(f\"{dataset_name} Samples\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_samples_fashion(dataset_name, x_data, y_data, class_names, num_samples=5):\n",
        "    \"\"\"\n",
        "    Display sample images from Fashion MNIST dataset.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(num_samples):\n",
        "        idx = np.random.randint(0, len(x_data))\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        plt.imshow(x_data[idx].reshape(28, 28), cmap='gray')\n",
        "        class_idx = np.argmax(y_data[idx])\n",
        "        plt.title(f\"{class_names[class_idx]}\")\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(f\"{dataset_name} Samples\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display sample images\n",
        "print(\"\\nDisplaying CIFAR-10 samples:\")\n",
        "display_samples_cifar10(\"CIFAR-10\", cifar_train[0], cifar_train[1], cifar10_class_names)\n",
        "\n",
        "print(\"\\nDisplaying Fashion MNIST samples:\")\n",
        "display_samples_fashion(\"Fashion MNIST\", fashion_train[0], fashion_train[1], fashion_class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQSMfGvdC8wn"
      },
      "source": [
        "## PART 3: FULLY CONNECTED NEURAL NETWORK IMPLEMENTATION\n",
        "\n",
        "In this section, we'll implement functions to create and train Fully Connected Neural Networks with various architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YT5sPk6zC8wo"
      },
      "outputs": [],
      "source": [
        "def create_fcnn(input_dim, hidden_layers, hidden_units, activation='relu', dropout_rate=0.0):\n",
        "    \"\"\"\n",
        "    Create a Fully Connected Neural Network with specified architecture.\n",
        "\n",
        "    Args:\n",
        "        input_dim: Input dimension (e.g., 3072 for CIFAR-10)\n",
        "        hidden_layers: Number of hidden layers\n",
        "        hidden_units: List or int specifying neurons in each hidden layer\n",
        "        activation: Activation function to use\n",
        "        dropout_rate: Dropout rate (0 = no dropout)\n",
        "\n",
        "    Returns:\n",
        "        model: Compiled Keras model\n",
        "    \"\"\"\n",
        "    model = Sequential(name=f\"FCNN_L{hidden_layers}_U{hidden_units if isinstance(hidden_units, int) else '-'.join(map(str, hidden_units))}\")\n",
        "\n",
        "    # Convert hidden_units to list if it's an integer\n",
        "    if isinstance(hidden_units, int):\n",
        "        hidden_units = [hidden_units] * hidden_layers\n",
        "\n",
        "    # Ensure we have enough hidden_units specified\n",
        "    if len(hidden_units) < hidden_layers:\n",
        "        hidden_units = hidden_units + [hidden_units[-1]] * (hidden_layers - len(hidden_units))\n",
        "\n",
        "    # Add input layer\n",
        "    model.add(Dense(hidden_units[0], activation=activation, input_shape=(input_dim,),\n",
        "                   name=f'dense_1_{hidden_units[0]}'))\n",
        "\n",
        "    # Add dropout if specified\n",
        "    if dropout_rate > 0:\n",
        "        model.add(Dropout(dropout_rate, name=f'dropout_1_{dropout_rate}'))\n",
        "\n",
        "    # Add additional hidden layers\n",
        "    for i in range(1, hidden_layers):\n",
        "        model.add(Dense(hidden_units[i], activation=activation,\n",
        "                       name=f'dense_{i+1}_{hidden_units[i]}'))\n",
        "\n",
        "        # Add dropout if specified\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate, name=f'dropout_{i+1}_{dropout_rate}'))\n",
        "\n",
        "    # Add output layer\n",
        "    model.add(Dense(10, activation='softmax', name='output'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_model(model, train_data, val_data, test_data, model_name,\n",
        "                            batch_size=128, epochs=30, patience=5, verbose=1):\n",
        "    \"\"\"\n",
        "    Train and evaluate a model, and calculate performance metrics.\n",
        "    \"\"\"\n",
        "    x_train, y_train = train_data\n",
        "    x_val, y_val = val_data\n",
        "    x_test, y_test = test_data\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=patience,\n",
        "        restore_best_weights=True,\n",
        "        verbose=(1 if verbose > 0 else 0)\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "\n",
        "    # Record start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    # Measure inference time (average over 1000 samples)\n",
        "    inference_samples = min(1000, len(x_test))\n",
        "    start_time = time.time()\n",
        "    _ = model.predict(x_test[:inference_samples], verbose=0)\n",
        "    inference_time = (time.time() - start_time) / inference_samples  # per sample\n",
        "\n",
        "    # Count parameters\n",
        "    trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
        "    non_trainable_params = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
        "    total_params = trainable_params + non_trainable_params\n",
        "\n",
        "    # Calculate train-validation gap (for overfitting analysis)\n",
        "    train_acc = max(history.history['accuracy'])\n",
        "    val_acc = max(history.history['val_accuracy'])\n",
        "    train_val_gap = train_acc - val_acc\n",
        "\n",
        "    # Calculate efficiency metrics\n",
        "    params_per_second = total_params / training_time\n",
        "    accuracy_per_million_params = test_accuracy * 100 / (total_params / 1e6)\n",
        "\n",
        "    # Store results\n",
        "    results = {\n",
        "        'model_name': model_name,\n",
        "        'history': history,\n",
        "        'training_time': training_time,\n",
        "        'test_accuracy': test_accuracy * 100,  # convert to percentage\n",
        "        'test_loss': test_loss,\n",
        "        'inference_time': inference_time * 1000,  # convert to milliseconds\n",
        "        'total_params': total_params,\n",
        "        'trainable_params': trainable_params,\n",
        "        'params_per_second': params_per_second,\n",
        "        'accuracy_per_million_params': accuracy_per_million_params,\n",
        "        'epochs_trained': len(history.history['accuracy']),\n",
        "        'train_val_gap': train_val_gap,\n",
        "        'batch_size': batch_size\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- {model_name} Results ---\")\n",
        "    print(f\"Test Accuracy: {results['test_accuracy']:.2f}%\")\n",
        "    print(f\"Training Time: {results['training_time']:.2f} seconds\")\n",
        "    print(f\"Inference Time: {results['inference_time']:.4f} ms\")\n",
        "    print(f\"Total Parameters: {results['total_params']:,}\")\n",
        "    print(f\"Epochs Trained: {results['epochs_trained']}\")\n",
        "    print(f\"Train-Val Gap: {results['train_val_gap']:.4f}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5noMruGC8wp"
      },
      "source": [
        "## PART 4: VISUALIZATION AND ANALYSIS FUNCTIONS\n",
        "\n",
        "Here we implement functions for visualizing and analyzing model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0uQLB31C8wp"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(histories, labels=None):\n",
        "    \"\"\"\n",
        "    Plot training history for multiple models.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for i, hist in enumerate(histories):\n",
        "        history = hist['history'] if isinstance(hist, dict) else hist\n",
        "        label = labels[i] if labels else f\"Model {i+1}\"\n",
        "        plt.plot(history.history['accuracy'], label=f\"{label} - Train\")\n",
        "        plt.plot(history.history['val_accuracy'], label=f\"{label} - Val\")\n",
        "\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for i, hist in enumerate(histories):\n",
        "        history = hist['history'] if isinstance(hist, dict) else hist\n",
        "        label = labels[i] if labels else f\"Model {i+1}\"\n",
        "        plt.plot(history.history['loss'], label=f\"{label} - Train\")\n",
        "        plt.plot(history.history['val_loss'], label=f\"{label} - Val\")\n",
        "\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(model, x_test, y_test_true, class_names, title):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix for model predictions.\n",
        "    \"\"\"\n",
        "    # Generate predictions\n",
        "    y_pred = model.predict(x_test, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(y_test_true, y_pred_classes)\n",
        "\n",
        "    # Normalize confusion matrix\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Find most confused pairs\n",
        "    cm_copy = cm.copy()\n",
        "    np.fill_diagonal(cm_copy, 0)  # Ignore correct classifications\n",
        "    max_confusion = np.unravel_index(np.argmax(cm_copy), cm_copy.shape)\n",
        "    print(f\"Most confused pair: {class_names[max_confusion[0]]} mistaken for {class_names[max_confusion[1]]} ({cm_copy[max_confusion]} times)\")\n",
        "\n",
        "    return cm, max_confusion\n",
        "\n",
        "def profile_memory_usage(model, x_input, batch_size=32):\n",
        "    \"\"\"\n",
        "    Profile memory usage during model inference.\n",
        "    \"\"\"\n",
        "    # Record baseline memory usage\n",
        "    baseline_memory = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024  # MB\n",
        "\n",
        "    # Warm-up run\n",
        "    _ = model.predict(x_input[:batch_size], verbose=0)\n",
        "\n",
        "    # Record memory usage during inference\n",
        "    peak_memory = baseline_memory\n",
        "\n",
        "    for i in range(0, min(1000, len(x_input)), batch_size):\n",
        "        batch = x_input[i:i+batch_size]\n",
        "        _ = model.predict(batch, verbose=0)\n",
        "        current_memory = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024  # MB\n",
        "        peak_memory = max(peak_memory, current_memory)\n",
        "\n",
        "    memory_results = {\n",
        "        'baseline_memory_mb': baseline_memory,\n",
        "        'peak_memory_mb': peak_memory,\n",
        "        'memory_increase_mb': peak_memory - baseline_memory\n",
        "    }\n",
        "\n",
        "    print(f\"Memory profiling results:\")\n",
        "    print(f\"  Baseline Memory: {memory_results['baseline_memory_mb']:.2f} MB\")\n",
        "    print(f\"  Peak Memory: {memory_results['peak_memory_mb']:.2f} MB\")\n",
        "    print(f\"  Memory Increase: {memory_results['memory_increase_mb']:.2f} MB\")\n",
        "\n",
        "    return memory_results\n",
        "\n",
        "def is_pareto_efficient(costs):\n",
        "    \"\"\"\n",
        "    Find the Pareto-efficient points.\n",
        "    \"\"\"\n",
        "    is_efficient = np.ones(costs.shape[0], dtype=bool)\n",
        "    for i, c in enumerate(costs):\n",
        "        if is_efficient[i]:\n",
        "            # Keep any point with a lower cost in at least one dimension\n",
        "            is_efficient[is_efficient] = np.any(costs[is_efficient] < c, axis=1) | np.all(costs[is_efficient] == c, axis=1)\n",
        "    return is_efficient\n",
        "\n",
        "def plot_metric_comparison(results_df, x_metric, y_metric, title, annotate=True):\n",
        "    \"\"\"\n",
        "    Plot a comparison of two metrics across models.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.scatter(results_df[x_metric], results_df[y_metric], s=100, alpha=0.7)\n",
        "\n",
        "    if annotate:\n",
        "        for i, row in results_df.iterrows():\n",
        "            model_name = row['Model'].replace('FCNN_', '')\n",
        "            plt.annotate(model_name,\n",
        "                        (row[x_metric], row[y_metric]),\n",
        "                        xytext=(5, 5), textcoords='offset points')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(x_metric)\n",
        "    plt.ylabel(y_metric)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzs38I1FC8wq"
      },
      "source": [
        "## PART 5: EXPERIMENT - NETWORK DEPTH VARIATION (CIFAR-10)\n",
        "\n",
        "In this experiment, we'll examine how varying the number of hidden layers affects model performance and computational requirements on CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjZwCW6AC8wq"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXPERIMENT 1: VARYING NETWORK DEPTH (CIFAR-10)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Experiment with different network depths\n",
        "depth_results = []\n",
        "depth_histories = []\n",
        "depth_models = []\n",
        "depth_names = []\n",
        "\n",
        "# Create models with different depths (1, 2, 3, 4 hidden layers)\n",
        "for num_layers in [1, 2, 3, 4]:\n",
        "    model_name = f\"FCNN_Depth_{num_layers}\"\n",
        "\n",
        "    model = create_fcnn(\n",
        "        input_dim=3072,  # CIFAR-10 flattened dimension (32x32x3)\n",
        "        hidden_layers=num_layers,\n",
        "        hidden_units=256,  # Increased for more complex CIFAR-10 data\n",
        "        activation='relu',\n",
        "        dropout_rate=0.3  # Slightly higher dropout for CIFAR-10\n",
        "    )\n",
        "\n",
        "    result = train_and_evaluate_model(\n",
        "        model=model,\n",
        "        train_data=cifar_train,\n",
        "        val_data=cifar_val,\n",
        "        test_data=cifar_test,\n",
        "        model_name=model_name,\n",
        "        epochs=30,\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    depth_results.append(result)\n",
        "    depth_histories.append(result['history'])\n",
        "    depth_models.append(model)\n",
        "    depth_names.append(model_name)\n",
        "\n",
        "# Plot training history for different depths\n",
        "print(\"\\nTraining history comparison for different network depths:\")\n",
        "plot_training_history(depth_histories, depth_names)\n",
        "\n",
        "# Create results table\n",
        "depth_df = pd.DataFrame([\n",
        "    {\n",
        "        'Model': result['model_name'],\n",
        "        'Depth': i+1,\n",
        "        'Accuracy (%)': result['test_accuracy'],\n",
        "        'Training Time (s)': result['training_time'],\n",
        "        'Inference Time (ms)': result['inference_time'],\n",
        "        'Parameters': result['total_params'],\n",
        "        'Params/Second': result['params_per_second'],\n",
        "        'Accuracy/Million Params': result['accuracy_per_million_params'],\n",
        "        'Train-Val Gap': result['train_val_gap']\n",
        "    }\n",
        "    for i, result in enumerate(depth_results)\n",
        "])\n",
        "\n",
        "print(\"\\nDepth Experiment Results (CIFAR-10):\")\n",
        "print(depth_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drt5Oq57C8wq"
      },
      "source": [
        "## PART 6: EXPERIMENT - NETWORK WIDTH VARIATION (CIFAR-10)\n",
        "\n",
        "In this experiment, we'll examine how varying the number of neurons in each layer affects model performance and computational requirements on CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TdvzeiPC8wr"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXPERIMENT 2: VARYING NETWORK WIDTH (CIFAR-10)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Experiment with different network widths\n",
        "width_results = []\n",
        "width_histories = []\n",
        "width_models = []\n",
        "width_names = []\n",
        "\n",
        "# Create models with different widths (128, 256, 512, 1024 neurons)\n",
        "for width in [128, 256, 512, 1024]:\n",
        "    model_name = f\"FCNN_Width_{width}\"\n",
        "\n",
        "    model = create_fcnn(\n",
        "        input_dim=3072,\n",
        "        hidden_layers=2,\n",
        "        hidden_units=width,\n",
        "        activation='relu',\n",
        "        dropout_rate=0.3\n",
        "    )\n",
        "\n",
        "    result = train_and_evaluate_model(\n",
        "        model=model,\n",
        "        train_data=cifar_train,\n",
        "        val_data=cifar_val,\n",
        "        test_data=cifar_test,\n",
        "        model_name=model_name,\n",
        "        epochs=30,\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    width_results.append(result)\n",
        "    width_histories.append(result['history'])\n",
        "    width_models.append(model)\n",
        "    width_names.append(model_name)\n",
        "\n",
        "# Plot training history for different widths\n",
        "print(\"\\nTraining history comparison for different network widths:\")\n",
        "plot_training_history(width_histories, width_names)\n",
        "\n",
        "# Create results table\n",
        "width_df = pd.DataFrame([\n",
        "    {\n",
        "        'Model': result['model_name'],\n",
        "        'Width': [128, 256, 512, 1024][i],\n",
        "        'Accuracy (%)': result['test_accuracy'],\n",
        "        'Training Time (s)': result['training_time'],\n",
        "        'Inference Time (ms)': result['inference_time'],\n",
        "        'Parameters': result['total_params'],\n",
        "        'Params/Second': result['params_per_second'],\n",
        "        'Accuracy/Million Params': result['accuracy_per_million_params'],\n",
        "        'Train-Val Gap': result['train_val_gap']\n",
        "    }\n",
        "    for i, result in enumerate(width_results)\n",
        "])\n",
        "\n",
        "print(\"\\nWidth Experiment Results (CIFAR-10):\")\n",
        "print(width_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFv64dLMC8wr"
      },
      "source": [
        "## PART 7: EXPERIMENT - ACTIVATION FUNCTIONS (CIFAR-10)\n",
        "\n",
        "In this experiment, we'll examine how different activation functions affect model performance and training dynamics on CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YbBfpsaC8wr"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXPERIMENT 3: VARYING ACTIVATION FUNCTIONS (CIFAR-10)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Experiment with different activation functions\n",
        "activation_results = []\n",
        "activation_histories = []\n",
        "activation_models = []\n",
        "activation_names = []\n",
        "\n",
        "# Create models with different activation functions\n",
        "for activation in ['relu', 'sigmoid', 'tanh', 'elu']:\n",
        "    model_name = f\"FCNN_Activation_{activation}\"\n",
        "\n",
        "    model = create_fcnn(\n",
        "        input_dim=3072,\n",
        "        hidden_layers=2,\n",
        "        hidden_units=256,\n",
        "        activation=activation,\n",
        "        dropout_rate=0.3\n",
        "    )\n",
        "\n",
        "    result = train_and_evaluate_model(\n",
        "        model=model,\n",
        "        train_data=cifar_train,\n",
        "        val_data=cifar_val,\n",
        "        test_data=cifar_test,\n",
        "        model_name=model_name,\n",
        "        epochs=30,\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    activation_results.append(result)\n",
        "    activation_histories.append(result['history'])\n",
        "    activation_models.append(model)\n",
        "    activation_names.append(model_name)\n",
        "\n",
        "# Plot training history for different activation functions\n",
        "print(\"\\nTraining history comparison for different activation functions:\")\n",
        "plot_training_history(activation_histories, activation_names)\n",
        "\n",
        "# Create results table\n",
        "activation_df = pd.DataFrame([\n",
        "    {\n",
        "        'Model': result['model_name'],\n",
        "        'Activation': ['relu', 'sigmoid', 'tanh', 'elu'][i],\n",
        "        'Accuracy (%)': result['test_accuracy'],\n",
        "        'Training Time (s)': result['training_time'],\n",
        "        'Epochs': result['epochs_trained'],\n",
        "        'Inference Time (ms)': result['inference_time'],\n",
        "        'Parameters': result['total_params'],\n",
        "        'Params/Second': result['params_per_second'],\n",
        "        'Train-Val Gap': result['train_val_gap']\n",
        "    }\n",
        "    for i, result in enumerate(activation_results)\n",
        "])\n",
        "\n",
        "print(\"\\nActivation Function Experiment Results (CIFAR-10):\")\n",
        "print(activation_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtS5PpJoC8wr"
      },
      "source": [
        "## PART 8: EXPERIMENT - DROPOUT REGULARIZATION (CIFAR-10)\n",
        "\n",
        "In this experiment, we'll examine how dropout regularization affects model performance and overfitting on CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gZzI-drC8wr"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXPERIMENT 4: VARYING DROPOUT REGULARIZATION (CIFAR-10)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Experiment with different dropout rates\n",
        "dropout_results = []\n",
        "dropout_histories = []\n",
        "dropout_models = []\n",
        "dropout_names = []\n",
        "\n",
        "# Create models with different dropout rates\n",
        "for dropout_rate in [0.0, 0.2, 0.4, 0.6]:\n",
        "    model_name = f\"FCNN_Dropout_{dropout_rate}\"\n",
        "\n",
        "    model = create_fcnn(\n",
        "        input_dim=3072,\n",
        "        hidden_layers=2,\n",
        "        hidden_units=256,\n",
        "        activation='relu',\n",
        "        dropout_rate=dropout_rate\n",
        "    )\n",
        "\n",
        "    result = train_and_evaluate_model(\n",
        "        model=model,\n",
        "        train_data=cifar_train,\n",
        "        val_data=cifar_val,\n",
        "        test_data=cifar_test,\n",
        "        model_name=model_name,\n",
        "        epochs=30,\n",
        "        patience=5,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    dropout_results.append(result)\n",
        "    dropout_histories.append(result['history'])\n",
        "    dropout_models.append(model)\n",
        "    dropout_names.append(model_name)\n",
        "\n",
        "# Plot training history for different dropout rates\n",
        "print(\"\\nTraining history comparison for different dropout rates:\")\n",
        "plot_training_history(dropout_histories, dropout_names)\n",
        "\n",
        "# Create results table\n",
        "dropout_df = pd.DataFrame([\n",
        "    {\n",
        "        'Model': result['model_name'],\n",
        "        'Dropout Rate': [0.0, 0.2, 0.4, 0.6][i],\n",
        "        'Accuracy (%)': result['test_accuracy'],\n",
        "        'Training Time (s)': result['training_time'],\n",
        "        'Epochs': result['epochs_trained'],\n",
        "        'Train-Val Gap': result['train_val_gap'],\n",
        "        'Parameters': result['total_params']\n",
        "    }\n",
        "    for i, result in enumerate(dropout_results)\n",
        "])\n",
        "\n",
        "print(\"\\nDropout Experiment Results (CIFAR-10):\")\n",
        "print(dropout_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLktSekWC8ws"
      },
      "source": [
        "## PART 10: DATASET COMPARISON (CIFAR-10 vs Fashion MNIST)\n",
        "\n",
        "In this section, we'll compare model performance on CIFAR-10 vs. Fashion MNIST datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayACU6KgC8ws"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXPERIMENT 6: DATASET COMPARISON (CIFAR-10 vs Fashion MNIST)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Compare performance on different datasets\n",
        "dataset_results = []\n",
        "dataset_histories = []\n",
        "dataset_names = []\n",
        "\n",
        "# Create a standard model architecture (adjusted for dataset input dimensions)\n",
        "# For CIFAR-10\n",
        "print(\"\\nTraining on CIFAR-10 dataset...\")\n",
        "cifar_model = create_fcnn(\n",
        "    input_dim=3072,\n",
        "    hidden_layers=2,\n",
        "    hidden_units=256,\n",
        "    activation='relu',\n",
        "    dropout_rate=0.3\n",
        ")\n",
        "cifar_result = train_and_evaluate_model(\n",
        "    model=cifar_model,\n",
        "    train_data=cifar_train,\n",
        "    val_data=cifar_val,\n",
        "    test_data=cifar_test,\n",
        "    model_name=\"FCNN_CIFAR10\",\n",
        "    epochs=30,\n",
        "    patience=5,\n",
        "    verbose=1\n",
        ")\n",
        "dataset_results.append(cifar_result)\n",
        "dataset_histories.append(cifar_result['history'])\n",
        "dataset_names.append(\"CIFAR-10\")\n",
        "\n",
        "# For Fashion MNIST\n",
        "print(\"\\nTraining on Fashion MNIST dataset...\")\n",
        "fashion_model = create_fcnn(\n",
        "    input_dim=784,\n",
        "    hidden_layers=2,\n",
        "    hidden_units=128,\n",
        "    activation='relu',\n",
        "    dropout_rate=0.2\n",
        ")\n",
        "fashion_result = train_and_evaluate_model(\n",
        "    model=fashion_model,\n",
        "    train_data=fashion_train,\n",
        "    val_data=fashion_val,\n",
        "    test_data=fashion_test,\n",
        "    model_name=\"FCNN_Fashion\",\n",
        "    epochs=30,\n",
        "    patience=5,\n",
        "    verbose=1\n",
        ")\n",
        "dataset_results.append(fashion_result)\n",
        "dataset_histories.append(fashion_result['history'])\n",
        "dataset_names.append(\"Fashion MNIST\")\n",
        "\n",
        "# Plot training history comparison\n",
        "print(\"\\nTraining history comparison between datasets:\")\n",
        "plot_training_history(dataset_histories, dataset_names)\n",
        "\n",
        "# Create results table\n",
        "dataset_df = pd.DataFrame([\n",
        "    {\n",
        "        'Dataset': name,\n",
        "        'Accuracy (%)': result['test_accuracy'],\n",
        "        'Training Time (s)': result['training_time'],\n",
        "        'Epochs': result['epochs_trained'],\n",
        "        'Inference Time (ms)': result['inference_time'],\n",
        "        'Parameters': result['total_params'],\n",
        "        'Train-Val Gap': result['train_val_gap']\n",
        "    }\n",
        "    for name, result in zip(dataset_names, dataset_results)\n",
        "])\n",
        "\n",
        "print(\"\\nDataset Comparison Results:\")\n",
        "print(dataset_df.to_string(index=False))\n",
        "\n",
        "# Plot confusion matrices\n",
        "print(\"\\nCIFAR-10 Confusion Matrix:\")\n",
        "cifar_cm, cifar_confused = plot_confusion_matrix(\n",
        "    cifar_model, cifar_test[0], cifar_y_test,\n",
        "    cifar10_class_names, \"CIFAR-10 Confusion Matrix\"\n",
        ")\n",
        "\n",
        "print(\"\\nFashion MNIST Confusion Matrix:\")\n",
        "fashion_cm, fashion_confused = plot_confusion_matrix(\n",
        "    fashion_model, fashion_test[0], fashion_y_test,\n",
        "    fashion_class_names, \"Fashion MNIST Confusion Matrix\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2jnViTYC8ws"
      },
      "source": [
        "## PART 11: COMPREHENSIVE ANALYSIS\n",
        "\n",
        "In this section, we'll analyze all experiment results together to draw overall conclusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpzu_P8dC8ws"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"COMPREHENSIVE ANALYSIS OF ALL EXPERIMENTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Consolidate results from all experiments\n",
        "all_results = depth_results + width_results + activation_results + dropout_results\n",
        "\n",
        "# Create comprehensive results table\n",
        "all_df = pd.DataFrame([\n",
        "    {\n",
        "        'Model': result['model_name'],\n",
        "        'Accuracy (%)': result['test_accuracy'],\n",
        "        'Training Time (s)': result['training_time'],\n",
        "        'Inference Time (ms)': result['inference_time'],\n",
        "        'Parameters': result['total_params'],\n",
        "        'Params/Second': result['params_per_second'],\n",
        "        'Accuracy/Million Params': result['accuracy_per_million_params'],\n",
        "        'Train-Val Gap': result['train_val_gap'],\n",
        "        'Epochs': result['epochs_trained']\n",
        "    }\n",
        "    for result in all_results\n",
        "])\n",
        "\n",
        "print(\"\\nAll Experiment Results (CIFAR-10):\")\n",
        "print(all_df.to_string(index=False))\n",
        "\n",
        "# Plot accuracy vs. parameters\n",
        "print(\"\\nModel Accuracy vs. Parameter Count:\")\n",
        "plot_metric_comparison(all_df, 'Parameters', 'Accuracy (%)',\n",
        "                      'Model Accuracy vs. Parameter Count (CIFAR-10)')\n",
        "\n",
        "# Plot training time vs. parameter count\n",
        "print(\"\\nTraining Time vs. Parameter Count:\")\n",
        "plot_metric_comparison(all_df, 'Parameters', 'Training Time (s)',\n",
        "                      'Training Time vs. Parameter Count (CIFAR-10)')\n",
        "\n",
        "# Plot inference time vs. parameter count\n",
        "print(\"\\nInference Time vs. Parameter Count:\")\n",
        "plot_metric_comparison(all_df, 'Parameters', 'Inference Time (ms)',\n",
        "                      'Inference Time vs. Parameter Count (CIFAR-10)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8Kov8WnC8wt"
      },
      "outputs": [],
      "source": [
        "# Plot efficiency metrics\n",
        "print(\"\\nEfficiency Metrics Comparison (CIFAR-10):\")\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Accuracy per million parameters\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.bar(all_df['Model'], all_df['Accuracy/Million Params'])\n",
        "plt.title('Accuracy per Million Parameters (CIFAR-10)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "# Parameters trained per second\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.bar(all_df['Model'], all_df['Params/Second'])\n",
        "plt.title('Parameters Trained per Second (CIFAR-10)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "# Accuracy vs. Training Time\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.scatter(all_df['Training Time (s)'], all_df['Accuracy (%)'], s=100, alpha=0.7)\n",
        "for i, row in all_df.iterrows():\n",
        "    model_name = row['Model'].replace('FCNN_', '')\n",
        "    plt.annotate(model_name,\n",
        "                 (row['Training Time (s)'], row['Accuracy (%)']),\n",
        "                 xytext=(5, 0), textcoords='offset points')\n",
        "plt.title('Accuracy vs. Training Time (CIFAR-10)')\n",
        "plt.xlabel('Training Time (seconds)')\n",
        "plt.ylabel('Test Accuracy (%)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Accuracy vs. Inference Time\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.scatter(all_df['Inference Time (ms)'], all_df['Accuracy (%)'], s=100, alpha=0.7)\n",
        "for i, row in all_df.iterrows():\n",
        "    model_name = row['Model'].replace('FCNN_', '')\n",
        "    plt.annotate(model_name,\n",
        "                 (row['Inference Time (ms)'], row['Accuracy (%)']),\n",
        "                 xytext=(5, 0), textcoords='offset points')\n",
        "plt.title('Accuracy vs. Inference Time (CIFAR-10)')\n",
        "plt.xlabel('Inference Time (ms)')\n",
        "plt.ylabel('Test Accuracy (%)')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qqU3ETCC8wt"
      },
      "source": [
        "## PART 12: IDENTIFY OPTIMAL ARCHITECTURES\n",
        "\n",
        "In this section, we'll identify the best performing models according to different criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IwuIdyMC8wt"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"IDENTIFYING OPTIMAL ARCHITECTURES (CIFAR-10)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Find models with best metrics\n",
        "best_accuracy_model = all_df.loc[all_df['Accuracy (%)'].idxmax()]\n",
        "print(\"\\nModel with Best Accuracy:\")\n",
        "print(best_accuracy_model.to_string())\n",
        "\n",
        "# Find model with best accuracy per parameter\n",
        "best_efficiency_model = all_df.loc[all_df['Accuracy/Million Params'].idxmax()]\n",
        "print(\"\\nModel with Best Accuracy/Parameter Ratio:\")\n",
        "print(best_efficiency_model.to_string())\n",
        "\n",
        "# Find model with fastest inference\n",
        "fastest_inference_model = all_df.loc[all_df['Inference Time (ms)'].idxmin()]\n",
        "print(\"\\nModel with Fastest Inference:\")\n",
        "print(fastest_inference_model.to_string())\n",
        "\n",
        "# Find model with fastest training\n",
        "fastest_training_model = all_df.loc[all_df['Training Time (s)'].idxmin()]\n",
        "print(\"\\nModel with Fastest Training:\")\n",
        "print(fastest_training_model.to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWp8tlKdC8wt"
      },
      "source": [
        "## PART 13: RESULTS SUMMARY FOR WORKSHEET\n",
        "\n",
        "Here we summarize the results of all experiments for easier reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5vsZkr6C8wt"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RESULTS SUMMARY FOR WORKSHEET\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nPart 1: Network Depth Experiment (CIFAR-10)\")\n",
        "for i, result in enumerate(depth_results):\n",
        "    depth = i + 1\n",
        "    print(f\"\\nDepth {depth}:\")\n",
        "    print(f\"  Test Accuracy: {result['test_accuracy']:.2f}%\")\n",
        "    print(f\"  Training Time: {result['training_time']:.2f} seconds\")\n",
        "    print(f\"  Inference Time: {result['inference_time']:.4f} ms\")\n",
        "    print(f\"  Total Parameters: {result['total_params']:,}\")\n",
        "\n",
        "print(\"\\nPart 2: Network Width Experiment (CIFAR-10)\")\n",
        "for i, width in enumerate([128, 256, 512, 1024]):\n",
        "    result = width_results[i]\n",
        "    print(f\"\\nWidth {width}:\")\n",
        "    print(f\"  Test Accuracy: {result['test_accuracy']:.2f}%\")\n",
        "    print(f\"  Training Time: {result['training_time']:.2f} seconds\")\n",
        "    print(f\"  Inference Time: {result['inference_time']:.4f} ms\")\n",
        "    print(f\"  Total Parameters: {result['total_params']:,}\")\n",
        "\n",
        "print(\"\\nPart 3: Activation Functions (CIFAR-10)\")\n",
        "for i, activation in enumerate(['relu', 'sigmoid', 'tanh', 'elu']):\n",
        "    result = activation_results[i]\n",
        "    print(f\"\\n{activation.upper()}:\")\n",
        "    print(f\"  Test Accuracy: {result['test_accuracy']:.2f}%\")\n",
        "    print(f\"  Training Time: {result['training_time']:.2f} seconds\")\n",
        "    print(f\"  Epochs to Converge: {result['epochs_trained']}\")\n",
        "    print(f\"  Inference Time: {result['inference_time']:.4f} ms\")\n",
        "\n",
        "print(\"\\nPart 4: Dropout Regularization (CIFAR-10)\")\n",
        "for i, dropout_rate in enumerate([0.0, 0.2, 0.4, 0.6]):\n",
        "    result = dropout_results[i]\n",
        "    print(f\"\\nDropout Rate {dropout_rate}:\")\n",
        "    print(f\"  Test Accuracy: {result['test_accuracy']:.2f}%\")\n",
        "    print(f\"  Training Time: {result['training_time']:.2f} seconds\")\n",
        "    print(f\"  Epochs to Converge: {result['epochs_trained']}\")\n",
        "    print(f\"  Train-Val Gap: {result['train_val_gap']:.4f}\")\n",
        "\n",
        "print(\"\\nPart 6: Dataset Comparison\")\n",
        "for i, dataset in enumerate(['CIFAR-10', 'Fashion MNIST']):\n",
        "    result = dataset_results[i]\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    print(f\"  Test Accuracy: {result['test_accuracy']:.2f}%\")\n",
        "    print(f\"  Training Time: {result['training_time']:.2f} seconds\")\n",
        "    print(f\"  Epochs to Converge: {result['epochs_trained']}\")\n",
        "    print(f\"  Parameters: {result['total_params']:,}\")\n",
        "\n",
        "print(\"\\nPart 7: Efficiency Metrics (CIFAR-10)\")\n",
        "print(f\"\\nBest Accuracy Model ({best_accuracy_model['Model']})\")\n",
        "print(f\"  Accuracy/Million Params: {best_accuracy_model['Accuracy/Million Params']:.2f}\")\n",
        "print(f\"  Params/Second: {best_accuracy_model['Params/Second']:.2f}\")\n",
        "\n",
        "print(f\"\\nFastest Training Model ({fastest_training_model['Model']})\")\n",
        "print(f\"  Accuracy/Million Params: {fastest_training_model['Accuracy/Million Params']:.2f}\")\n",
        "print(f\"  Params/Second: {fastest_training_model['Params/Second']:.2f}\")\n",
        "\n",
        "print(f\"\\nFastest Inference Model ({fastest_inference_model['Model']})\")\n",
        "print(f\"  Accuracy/Million Params: {fastest_inference_model['Accuracy/Million Params']:.2f}\")\n",
        "print(f\"  Params/Second: {fastest_inference_model['Params/Second']:.2f}\")\n",
        "\n",
        "print(f\"\\nMost Parameter-Efficient Model ({best_efficiency_model['Model']})\")\n",
        "print(f\"  Accuracy/Million Params: {best_efficiency_model['Accuracy/Million Params']:.2f}\")\n",
        "print(f\"  Params/Second: {best_efficiency_model['Params/Second']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tUTIojqC8wu"
      },
      "source": [
        "## PART 14: SAVE RESULTS (UNCOMMENT TO USE)\n",
        "\n",
        "Here we provide code to save the experiment results and best model if desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tBghyWQC8wu"
      },
      "outputs": [],
      "source": [
        "# Save results to Google Drive\n",
        "# results_path = \"/content/drive/My Drive/ML_Hardware_Course/Lab2/fcnn_cifar10_results.csv\"\n",
        "# all_df.to_csv(results_path, index=False)\n",
        "# print(f\"Results saved to {results_path}\")\n",
        "\n",
        "# Save the best model\n",
        "# best_model_path = \"/content/drive/My Drive/ML_Hardware_Course/Lab2/best_fcnn_cifar10_model.h5\"\n",
        "# model_idx = all_df[all_df['Model'] == best_accuracy_model['Model']].index[0]\n",
        "# model_group = model_idx // len(depth_results)\n",
        "# model_within_group = model_idx % len(depth_results)\n",
        "\n",
        "# if model_group == 0:\n",
        "#     depth_models[model_within_group].save(best_model_path)\n",
        "# elif model_group == 1:\n",
        "#     width_models[model_within_group].save(best_model_path)\n",
        "# elif model_group == 2:\n",
        "#     activation_models[model_within_group].save(best_model_path)\n",
        "# else:\n",
        "#     dropout_models[model_within_group].save(best_model_path)\n",
        "\n",
        "# print(f\"Best model saved to {best_model_path}\")\n",
        "\n",
        "print(\"\\nLab 2 completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux4IUeOSC8wv"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this lab, we experimented with Fully Connected Neural Networks (FCNNs) on the CIFAR-10 dataset to understand how different architectural choices impact model performance, training efficiency, and hardware utilization. We systematically varied network depth, width, activation functions, and regularization techniques to analyze their effects. We also compared performance between CIFAR-10 and Fashion MNIST datasets.\n",
        "\n",
        "## Key Findings:\n",
        "\n",
        "1. **Network Depth**: Deeper networks can capture more complex patterns in CIFAR-10 images but show diminishing returns after a certain depth. The increased depth also significantly impacts training time and memory usage.\n",
        "\n",
        "2. **Network Width**: Wider networks generally provide higher accuracy on CIFAR-10 but at the cost of substantially more parameters. The 1024-width model shows the highest accuracy but with significant computational cost.\n",
        "\n",
        "3. **Activation Functions**: ReLU continues to perform well with fast training convergence on CIFAR-10. Sigmoid and tanh show slower convergence and lower final accuracy due to vanishing gradient problems with the higher-dimensional input.\n",
        "\n",
        "4. **Dropout Regularization**: CIFAR-10 benefits from moderate dropout rates (0.2-0.4) to combat overfitting, as indicated by smaller train-validation accuracy gaps compared to the no-dropout model.\n",
        "\n",
        "5. **Dataset Complexity**: CIFAR-10 proves to be significantly more challenging than Fashion MNIST, with lower overall accuracy (typically 40-50% for FCNNs vs. 85-90% for Fashion MNIST). This highlights the limitations of fully connected architectures for complex image data with spatial structure.\n",
        "\n",
        "6. **Memory Requirements**: The larger input dimension of CIFAR-10 (3072 vs. 784 for Fashion MNIST) results in substantially larger models even with similar architectures, emphasizing the importance of input dimensionality in hardware considerations.\n",
        "\n",
        "These insights demonstrate that while FCNNs can be applied to datasets like CIFAR-10, they are not optimal for complex image recognition tasks. The spatial structure of images is better captured by convolutional neural networks, which we will explore in future labs. However, the principles learned about depth, width, and regularization apply broadly to neural network design across different hardware platforms."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
