{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378d8b6f",
   "metadata": {},
   "source": [
    "# Lab 4a: Hardware Benchmarking (HW Accelerators Prespective)\n",
    "## Hardware for Machine Learning Course\n",
    "\n",
    "This notebook is to benchmark different HWs from their architecture prespective.\n",
    "Part-1 covers:\n",
    "1. Environment setup, Model and dataset preparation\n",
    "2. CPU performance benchmarking\n",
    "3. GPU performance benchmarking\n",
    "\n",
    "Part-2 covers:\n",
    "1. \n",
    "\n",
    "The lab will explore how a neural network model perform across different hardware platforms and how they can be optimized for specific deployment scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4612fb",
   "metadata": {},
   "source": [
    "## PART-1: LATENCY BENCHMARKING\n",
    "### PART 1-1: ENVIRONMENT SETUP\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and checking available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the needed libraries\n",
    "# assert if cuda was not chosen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb70de1",
   "metadata": {},
   "source": [
    "### PART 1-2: MODEL, DATASET PREPARATION, AND BUILDING HELPING FUNCTIONS\n",
    "Now we'll create our model architectures and prepare the CIFAR-10 dataset for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bcb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A CNN MODEL\n",
    "# PREPARE A SUBSET OF THE CIFAR-10 DATASET\n",
    "class CNNModel(nn.Module):\n",
    "    \"\"\"Simple CNN model for classification.\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),  # CIFAR-10 images are 32x32, after two poolings: 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        # Note: No softmax here as it's included in CrossEntropyLoss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "def load_and_prepare_cifar10(batch_size=32, train_fraction=0.1, val_fraction=0.1):\n",
    "    \"\"\"\n",
    "    Load and prepare a small portion of CIFAR-10 dataset.\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Batch size for dataloaders\n",
    "        train_fraction: Fraction of training data to use (0.0 to 1.0)\n",
    "        val_fraction: Fraction of training data to use for validation (0.0 to 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader: DataLoaders for each dataset split\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define transforms for data preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts to [0, 1] range\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))  # CIFAR-10 mean and std\n",
    "    ])\n",
    "    \n",
    "    # Download and load training dataset\n",
    "    full_trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    # Download and load test dataset\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    # Calculate sizes for training subset\n",
    "    total_train = len(full_trainset)\n",
    "    train_size = int(total_train * train_fraction)\n",
    "    val_size = int(total_train * val_fraction)\n",
    "    \n",
    "    # Create indices for random subset\n",
    "    indices = torch.randperm(total_train)\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    \n",
    "    # Create subset datasets\n",
    "    trainset = Subset(full_trainset, train_indices)\n",
    "    valset = Subset(full_trainset, val_indices)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    print(f\"Training samples: {len(trainset)}\")\n",
    "    print(f\"Validation samples: {len(valset)}\")\n",
    "    print(f\"Test samples: {len(testset)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def train(train_loader, val_loader, criterion, device, num_epochs = 5):\n",
    "    # Training loop\n",
    "    print(f\"Using device: {device}\")\n",
    "    # Create models\n",
    "    model = CNNModel(num_classes=10).to(device)\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize timing variables\n",
    "    total_training_time = 0\n",
    "    total_samples_processed = 0\n",
    "    epoch_metrics = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Start timing for this epoch\n",
    "        if device.type == 'cuda':\n",
    "            # CUDA events for GPU timing\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            start_event.record()\n",
    "        else:\n",
    "            # CPU timing\n",
    "            start_time = time.time()\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        # End timing for this epoch\n",
    "        if device.type == 'cuda':\n",
    "            end_event.record()\n",
    "            torch.cuda.synchronize()\n",
    "            epoch_time = start_event.elapsed_time(end_event) / 1000  # Convert to seconds\n",
    "        else:\n",
    "            epoch_time = time.time() - start_time\n",
    "        # Update totals\n",
    "        total_training_time += epoch_time\n",
    "        total_samples_processed += len(train_loader.dataset)\n",
    "        # Calculate samples per second for this epoch\n",
    "        samples_per_second = len(train_loader.dataset) / epoch_time\n",
    "        \n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Store epoch metrics\n",
    "        epoch_metrics.append({\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'epoch_time': epoch_time,\n",
    "            'samples_per_second': samples_per_second\n",
    "        })\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        print(f'Epoch Time: {epoch_time:.2f}s, Samples/sec: {samples_per_second:.2f}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "    # Calculate overall metrics\n",
    "    avg_samples_per_second = total_samples_processed / total_training_time\n",
    "    final_val_acc = epoch_metrics[-1]['val_acc']  # Last epoch's validation accuracy\n",
    "    \n",
    "    print(f\"\\nOverall Training Summary:\")\n",
    "    print(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "    print(f\"Average Samples/second: {avg_samples_per_second:.2f}\")\n",
    "    print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "    \n",
    "    return model, total_training_time, avg_samples_per_second, final_val_acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    \"\"\"Test the model.\"\"\"\n",
    "    model.eval()\n",
    "    test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fee23a",
   "metadata": {},
   "source": [
    "### PREPARING BENCHARKING FOR BOTH THE CPU AND THE GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b420b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available(), \"This notebook should not be run with a runtime other than a GPU\"\n",
    "cuda_device = torch.device('cuda')\n",
    "cpu_device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data (using 20% of training data: 10% for training, 10% for validation)\n",
    "train_loader, val_loader, test_loader = load_and_prepare_cifar10(\n",
    "    batch_size=32, \n",
    "    train_fraction=0.1,  # 10% of training data for training\n",
    "    val_fraction=0.1      # 10% of training data for validation\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Print CIFAR-10 class names for reference\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "            'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b01c21",
   "metadata": {},
   "source": [
    "### PART 1-3: BENCHMARKING THE CPU\n",
    "put some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99123463",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK THE EVALUATION ON BS 1 AND 64\n",
    "THE METRICS ARE LATENCY, SAMPLES/S, EVALUATION ACCURACY \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924370bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the cnn model using cpu\n",
    "cpu_trained_model, cpu_time, cpu_samples_per_sec, cpu_val_acc = train(train_loader, val_loader, criterion, cpu_device)\n",
    "# Final test\n",
    "cpu_test_loss, cpu_test_acc = test(cpu_trained_model, test_loader, criterion, cpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef290f3",
   "metadata": {},
   "source": [
    "### PART 1-4: BENCHMARKING THE GPU\n",
    "put some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK  THE EVALUATION ON BS 1 AND 64\n",
    "THE METRICS ARE LATENCY, SAMPLES/S, EVALUATION ACCURACY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the cnn model using gpu\n",
    "cuda_trained_model, cuda_time, cuda_samples_per_sec, cuda_val_acc = train(train_loader, val_loader, criterion, cuda_device)\n",
    "# Final test\n",
    "cuda_test_loss, cuda_test_acc = test(cuda_trained_model, test_loader, criterion, cuda_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb40c1",
   "metadata": {},
   "source": [
    "## Part-2: MODEL QUANTIZATION AND PRUNING\n",
    "In this part we will quantize and prune a model then benchmark its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c5106",
   "metadata": {},
   "source": [
    "### PART 2-1: BUILDING HELPING FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build one helping function for INT8 quantization and another for pruning.\n",
    "Do you retrain?? will you use the same old model? will you construct a new one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c846a",
   "metadata": {},
   "source": [
    "### PART 2-2: BENCHMARKING THE GPU WITH INT8 QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7273753",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEAT THE ACCURACY AND INFERNECE BENCHMARKING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e5b95",
   "metadata": {},
   "source": [
    "### PART 2-3: BENCHMARKING THE GPU WITH STRUCTURAL PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEAT THE ACCURACY AND INFERNECE BENCHMARKING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed146161",
   "metadata": {},
   "source": [
    "## Part-3: DEPLOYMENT FORMAT CONVERSION\n",
    "In this section, we'll convert our models to different formats suitable for various deployment scenarios, such as ONNX for cross-platform compatibility, SavedModel for TensorFlow Serving, and TensorFlow.js for web deployment.\n",
    "\n",
    "\n",
    "WILL WE CONSIDER TENSORFLOW OR PYTORCH???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
